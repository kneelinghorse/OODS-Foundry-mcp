Architectural Blueprint for a Secure MCP Tool Server for Design System Operations
Executive Summary
This report presents a comprehensive architectural blueprint for the design and implementation of a secure, high-performance Model Context Protocol (MCP) server. The primary objective of this server is to provide a minimal, schema-validated interface that safely exposes a suite of internal design-system operations (OODS) tools to advanced AI agent clients, specifically Anthropic's Claude and the OpenAI Agents SDK. The architecture prioritizes security, auditability, and performance to create a robust gateway for AI-driven system maintenance and governance.

The core recommendations establish a technology stack and a set of operational patterns designed for production readiness. The server foundation will be built on the Fastify web framework, selected for its superior throughput and low-overhead performance, coupled with Ajv for high-speed, native JSON Schema validation. This combination ensures that the server can handle a high volume of requests while strictly enforcing the tool contracts.

The execution model is founded on a principle of intentionality, where all tool invocations default to a safe dry-run mode. Write operations are only permitted when an explicit --apply flag is provided. To contain these operations, a multi-layered sandboxing strategy is defined. This strategy combines programmatic path canonicalization to enforce a strict filesystem "jail" within a designated /artifacts directory and the use of temporary Git branches for isolated, reviewable changes. All external tool execution is managed through a secure subprocess spawner that mitigates command injection vulnerabilities.

Finally, to ensure complete auditability and observability, the report specifies a detailed format for structured JSON transcripts of every tool execution, including redaction of sensitive data and an integrity hash. A formal error taxonomy is established to provide clear, machine-readable feedback to AI clients, enabling them to handle failures intelligently. This document serves as a definitive guide for the development team, providing the necessary schemas, code patterns, and configurations to build and deploy the MCP server.

Section 1: Core Server Architecture and Recommendations
The foundation of the MCP server dictates its performance, security posture, and maintainability. The choices of framework and validation library are not independent but are synergistic decisions that define the core characteristics of the service. This section outlines the recommended technology stack, justifying each component based on the project's specific requirements for a high-throughput, schema-first gateway.

1.1 Framework Selection: A Performance-Oriented Approach
The selection of a Node.js web framework is a critical architectural decision. The primary contenders, Express.js and Fastify, offer different philosophies and performance profiles. While Express is known for its minimalist API and vast ecosystem, its performance can degrade under significant load, handling approximately 20,000 requests per second (RPS) in benchmark scenarios. Furthermore, it lacks essential built-in features like schema validation, requiring third-party libraries that can introduce performance overhead and inconsistencies.   

Fastify, in contrast, is engineered explicitly for high performance and low overhead. Benchmarks consistently demonstrate that Fastify can handle over double the throughput of Express, often exceeding 50,000 RPS, with lower memory consumption. This performance advantage is achieved through optimized JSON handling, efficient routing algorithms, and a plugin-based architecture that encourages modularity without sacrificing speed.   

Crucially for this project, Fastify provides first-class, built-in support for JSON Schema validation. This feature is not an afterthought; it is deeply integrated into the framework's request lifecycle and is highly optimized. By defining schemas for routes, Fastify automatically validates incoming requests and can even accelerate JSON serialization for responses, a feature that directly aligns with the core requirement of a "schema-validated interface". Its modern design also offers superior TypeScript integration out of the box.   

Recommendation: Fastify is the unequivocally recommended framework. Its focus on performance, low overhead, and native, high-speed JSON Schema validation makes it the ideal foundation for a secure and efficient MCP gateway.

Table 1: Framework Comparison (Fastify vs. Express.js)

Feature	Express.js	Fastify	Justification for MCP Server
Performance (RPS)	~20,000	~50,000+	
Fastify's superior throughput is critical for a gateway that may serve multiple agents concurrently.

Memory Usage	Higher (~150 MB @ 10k connections)	Lower (~100 MB @ 10k connections)	
Lower memory footprint translates to better resource efficiency and lower operational costs.

JSON Schema Validation	Requires third-party libraries (e.g., express-validator)	Built-in, highly optimized using Ajv	
Native validation is a core project requirement; Fastify's integration is faster and more seamless.

TypeScript Support	Relies on community types (@types/express)	First-class, designed with TypeScript in mind	
Better type safety and developer experience, reducing potential for runtime errors.

Extensibility Model	Linear middleware chain	Plugin-based architecture	
Fastify's plugins offer better encapsulation and performance isolation, suiting a modular tool-based server.

Ecosystem Maturity	Very large and mature	Growing, with curated official plugins	
While Express has a larger ecosystem, Fastify's core plugins are sufficient and optimized for performance.

  
1.2 Schema Validation Library: Balancing Performance and Ergonomics
The choice of a schema validation library is intrinsically linked to the framework selection. The two leading candidates in the Node.js ecosystem are Ajv and Zod. Zod is lauded for its TypeScript-first developer experience, offering excellent type inference that couples validation schemas tightly with TypeScript types. However, Zod implements its own validation logic and does not adhere to the JSON Schema standard, which can create an impedance mismatch with tools and protocols that expect standard schemas. Furthermore, benchmarks show that Zod is significantly slower than other specialized validation libraries.   

Ajv, on the other hand, is the de facto standard for high-performance JSON Schema validation in JavaScript. It achieves its speed by pre-compiling schemas into highly efficient validation functions, making it ideal for performance-critical applications. While its direct use can have a steeper learning curve due to its reliance on raw JSON Schema syntax, this is mitigated by its integration into the chosen framework.   

The selection of Fastify makes this decision straightforward. Fastify uses Ajv as its default validation engine, leveraging its performance to provide schema validation with near-zero overhead. By adopting Ajv for defining tool contracts, the server architecture aligns perfectly with the framework's optimized path. This synergy ensures that validation is not a bottleneck but a core, high-speed feature of the request lifecycle. It avoids the performance penalty and architectural dissonance of introducing a separate, non-standard validation library like Zod.   

Recommendation: Ajv is the recommended validation library. Its industry-leading performance and native, optimized integration with Fastify make it the superior choice for this performance-sensitive gateway application.

1.3 Foundational Server Skeleton (Node.js/TypeScript)
To ensure a robust and maintainable codebase, a well-defined project structure and strict TypeScript configuration are essential from the outset.

1.3.1 Project Structure
A logical directory structure will separate concerns and facilitate future expansion.

/
├── dist/                     # Compiled JavaScript output
├── src/                      # TypeScript source code
│   ├── core/                 # Core server logic, security, logging
│   │   ├── safe-spawn.ts     # Secure subprocess wrapper
│   │   ├── sandbox.ts        # Path sandboxing utilities
│   │   └── transcript.ts     # Transcript logging
│   ├── schemas/              # JSON schema definitions for tools
│   │   ├── tokens.build.ts
│   │   └──...
│   ├── tools/                # Tool implementation logic
│   │   ├── tokens.build.ts
│   │   └──...
│   ├── server.ts             # Main server entry point
│   └── types.ts              # Shared TypeScript types
├── artifacts/                # Sandbox directory for tool outputs
│   └── current-state/
├── package.json
└── tsconfig.json
1.3.2 TypeScript Configuration
A strict tsconfig.json configuration is non-negotiable for a production-grade service. It enables the compiler to catch a wide range of common errors at build time, enhancing code quality and reliability.   

tsconfig.json:

JSON

{
  "extends": "@tsconfig/node20/tsconfig.json",
  "compilerOptions": {
    "outDir": "dist",
    "module": "NodeNext",
    "moduleResolution": "NodeNext",
    "strict": true,
    "esModuleInterop": true,
    "forceConsistentCasingInFileNames": true,
    "noUnusedLocals": true,
    "noImplicitReturns": true,
    "resolveJsonModule": true
  },
  "include": ["src/**/*"],
  "exclude": ["node_modules", "dist"]
}
1.3.3 Core Server Implementation
The server's entry point will initialize the MCP server from the @modelcontextprotocol/sdk and connect it to a StdioServerTransport. The stdio transport is the standard mechanism for local clients like the OpenAI Agents SDK and Claude Desktop, where the client spawns the server as a subprocess and communicates over stdin and stdout.   

src/server.ts:

TypeScript

import { McpServer } from '@modelcontextprotocol/sdk/server/mcp.js';
import { StdioServerTransport } from '@modelcontextprotocol/sdk/server/stdio.js';
import { registerTools } from './tools'; // A function to register all tool handlers

async function main() {
  // 1. Initialize the MCP Server
  const server = new McpServer({
    name: 'OODS-Tool-Server',
    version: '1.0.0',
  });

  // 2. Register all tool definitions and their handlers
  // This function will contain the logic for defining schemas and implementations
  registerTools(server);

  // 3. Initialize the Stdio Transport
  const transport = new StdioServerTransport();

  // 4. Connect the server to the transport and begin listening
  try {
    await server.connect(transport);
    console.error(' Connected to stdio transport. Listening for requests.');
  } catch (error) {
    console.error(' Failed to connect to stdio transport:', error);
    process.exit(1);
  }

  // Handle graceful shutdown
  process.on('SIGINT', () => {
    console.error(' Shutting down...');
    transport.close();
    server.close();
    process.exit(0);
  });
}

main();
This skeleton provides a clean, robust starting point. The registerTools function will be the central location for defining the tool contracts and linking them to their respective implementation logic, as detailed in the following section.

Section 2: Defining the Tool Contract
The contract between the MCP server and its AI agent clients is defined by the tools it exposes. A well-defined contract is unambiguous, machine-readable, and provides the LLM with all the information it needs to correctly invoke a tool. This section specifies the structure of this contract using the MCP standard and provides concrete JSON Schema definitions for the target OODS toolset.

2.1 The MCP Tool Standard
The Model Context Protocol specifies a clear structure for defining tools. Each tool definition must include several key fields :   

name: A unique, machine-readable identifier for the tool (e.g., tokens.build).

description: A clear, human-readable description of the tool's purpose and functionality. This field is of paramount importance, as it is the primary text the LLM uses to determine whether a tool is appropriate for a given user request.

inputSchema: A valid JSON Schema object that defines the structure, types, and constraints of the arguments the tool accepts.

outputSchema: An optional JSON Schema describing the structure of the successful output from the tool. Providing this helps clients and models validate and correctly parse the tool's results.   

In alignment with the protocol's security recommendations, the server's design assumes a human-in-the-loop model. The dry-run vs. apply mechanism detailed in Section 3 serves as the technical implementation of this principle, ensuring that potentially destructive actions require explicit user confirmation before execution.   

2.2 JSON Schema Definitions for OODS Toolset
The following JSON Schemas define the contracts for the initial set of OODS tools. These schemas are designed to be strict (additionalProperties: false) to reject any extraneous parameters, enhancing security and predictability.

2.2.1 tokens.build Schema
This tool compiles design tokens from a source format into various distributable formats.

JSON

{
  "name": "tokens.build",
  "description": "Builds design tokens from source files into specified output formats like CSS, JS, and JSON. Defaults to a dry-run unless the '--apply' flag is used.",
  "inputSchema": {
    "type": "object",
    "properties": {
      "source": {
        "type": "string",
        "description": "Relative path to the source token definition file (e.g., 'tokens/colors.json')."
      },
      "platforms": {
        "type": "array",
        "items": { "type": "string", "enum": ["css", "js", "scss"] },
        "description": "An array of output platforms to build for.",
        "minItems": 1
      },
      "apply": {
        "type": "boolean",
        "description": "Set to true to execute the build and write files. Defaults to false (dry-run).",
        "default": false
      }
    },
    "required": ["source", "platforms"],
    "additionalProperties": false
  },
  "outputSchema": {
    "type": "object",
    "properties": {
      "success": { "type": "boolean" },
      "message": { "type": "string" },
      "artifacts": {
        "type": "array",
        "items": {
          "type": "object",
          "properties": {
            "platform": { "type": "string" },
            "path": { "type": "string" }
          },
          "required": ["platform", "path"]
        }
      }
    },
    "required": ["success", "message", "artifacts"]
  }
}
2.2.2 a11y.scan Schema
This tool performs an automated accessibility scan on a given URL or component. As a read-only operation, it does not require an apply flag.

JSON

{
  "name": "a11y.scan",
  "description": "Performs an automated accessibility (a11y) scan on a specified URL.",
  "inputSchema": {
    "type": "object",
    "properties": {
      "url": {
        "type": "string",
        "format": "uri",
        "description": "The publicly accessible URL to scan for accessibility issues."
      }
    },
    "required": ["url"],
    "additionalProperties": false
  },
  "outputSchema": {
    "type": "object",
    "properties": {
      "url": { "type": "string", "format": "uri" },
      "issueCount": { "type": "integer" },
      "issues": {
        "type": "array",
        "items": {
          "type": "object",
          "properties": {
            "id": { "type": "string" },
            "impact": { "type": "string", "enum": ["minor", "moderate", "serious", "critical"] },
            "description": { "type": "string" },
            "helpUrl": { "type": "string", "format": "uri" }
          },
          "required": ["id", "impact", "description"]
        }
      }
    },
    "required": ["url", "issueCount", "issues"]
  }
}
2.2.3 reviewKit.create Schema
This tool scaffolds a new review environment (e.g., a dedicated Storybook instance) for a feature.

JSON

{
  "name": "reviewKit.create",
  "description": "Creates a new, isolated review kit (e.g., a Storybook build) for a specific feature branch. Defaults to a dry-run unless the '--apply' flag is used.",
  "inputSchema": {
    "type": "object",
    "properties": {
      "featureName": {
        "type": "string",
        "description": "A short, URL-safe name for the feature (e.g., 'new-button-variant')."
      },
      "ticketId": {
        "type": "string",
        "pattern": "^[A-Z]+-[0-9]+$",
        "description": "The associated ticket ID (e.g., 'PROJ-123')."
      },
      "apply": {
        "type": "boolean",
        "description": "Set to true to create the review kit. Defaults to false (dry-run).",
        "default": false
      }
    },
    "required": ["featureName", "ticketId"],
    "additionalProperties": false
  },
  "outputSchema": {
    "type": "object",
    "properties": {
      "success": { "type": "boolean" },
      "message": { "type": "string" },
      "reviewKitUrl": {
        "type": "string",
        "format": "uri",
        "description": "The URL of the deployed review kit."
      },
      "branchName": {
        "type": "string",
        "description": "The name of the temporary git branch created for the review kit."
      }
    },
    "required": ["success", "message"]
  }
}
2.2.4 release.packVerify Schema
This tool simulates the package and verification steps of a release process.

JSON

{
  "name": "release.packVerify",
  "description": "Packs and verifies a release candidate for a given version number. Defaults to a dry-run unless the '--apply' flag is used to create a temporary git branch with the release artifacts.",
  "inputSchema": {
    "type": "object",
    "properties": {
      "version": {
        "type": "string",
        "pattern": "^(0|[1-9]\\d*)\\.(0|[1-9]\\d*)\\.(0|[1-9]\\d*)(?:-((?:0|[1-9]\\d*|\\d*[a-zA-Z-][0-9a-zA-Z-]*)(?:\\.(?:0|[1-9]\\d*|\\d*[a-zA-Z-][0-9a-zA-Z-]*))*))?(?:\\+([0-9a-zA-Z-]+(?:\\.[0-9a-zA-Z-]+)*))?$",
        "description": "The semantic version number for the release (e.g., '1.2.3')."
      },
      "apply": {
        "type": "boolean",
        "description": "Set to true to generate artifacts on a new git branch. Defaults to false (dry-run).",
        "default": false
      }
    },
    "required": ["version"],
    "additionalProperties": false
  },
  "outputSchema": {
    "type": "object",
    "properties": {
      "success": { "type": "boolean" },
      "version": { "type": "string" },
      "verificationChecks": {
        "type": "array",
        "items": {
          "type": "object",
          "properties": {
            "checkName": { "type": "string" },
            "passed": { "type": "boolean" },
            "details": { "type": "string" }
          },
          "required": ["checkName", "passed"]
        }
      },
      "branchName": {
        "type": "string",
        "description": "The temporary git branch created if 'apply' was true."
      }
    },
    "required": ["success", "version", "verificationChecks"]
  }
}
2.3 Integrating Schema Validation
With the schemas defined, they must be registered with the MCP server and enforced at runtime. The registerTools function (called from server.ts) is the ideal place to manage this. The MCP SDK's server.registerTool method accepts the schema and the handler function. The SDK, in conjunction with the underlying transport, will handle the validation of incoming tools/call requests against the registered inputSchema.

src/tools/index.ts:

TypeScript

import { McpServer } from '@modelcontextprotocol/sdk/server/mcp.js';
import Ajv from 'ajv';
import addFormats from 'ajv-formats';

// Import schemas and handlers
import { schema as tokensBuildSchema, handler as tokensBuildHandler } from './tokens.build';
import { schema as a11yScanSchema, handler as a11yScanHandler } from './a11y.scan';
//... import others

// Create a single Ajv instance for all tool validations
const ajv = new Ajv({ allErrors: true });
addFormats(ajv); // Add formats like 'uri'

export function registerTools(server: McpServer) {
  // A helper to register a tool, its schema, and its handler
  const addTool = (schema: any, handler: (params: any) => Promise<any>) => {
    // Pre-compile the validator for performance
    const validate = ajv.compile(schema.inputSchema);

    server.registerTool(
      schema.name,
      {
        description: schema.description,
        inputSchema: schema.inputSchema,
        outputSchema: schema.outputSchema,
      },
      async (params: unknown) => {
        // Runtime validation using the pre-compiled Ajv validator
        if (!validate(params)) {
          // This is a protocol-level error for invalid arguments
          throw new Error(`Invalid arguments: ${ajv.errorsText(validate.errors)}`);
        }
        // If valid, execute the tool's business logic
        return handler(params);
      }
    );
  };

  // Register each tool
  addTool(tokensBuildSchema, tokensBuildHandler);
  addTool(a11yScanSchema, a11yScanHandler);
  //... register others

  console.error(` Registered tools: ${server.getTools().map(t => t.name).join(', ')}`);
}
This pattern ensures that before any tool's business logic is executed, its inputs are rigorously validated against its contract, preventing a large class of errors and enhancing the server's security and stability.

Section 3: A Multi-Layered Secure Execution Model
Security is the paramount concern when exposing internal tools to an external agent, even a trusted one. A robust security model cannot rely on a single line of defense but must employ a multi-layered strategy that assumes untrusted input and confines execution at every stage. This section details the three core layers of this model: a logical contract based on intentionality (dry-run/apply), a strict filesystem and version control sandbox, and a secure method for spawning subprocesses.

3.1 Dry-Run and Apply Logic: The Principle of Intentionality
The foundational principle of the execution model is that no mutable action should occur by default. This forces the client (and its human operator) to be explicit about their intent to modify the system state.

3.1.1 Contract Definition
Every tool capable of performing a write operation (e.g., creating files, committing to git) MUST include an apply boolean parameter in its inputSchema.

Default Behavior: If the apply parameter is false or omitted, the tool MUST operate in dry-run mode.

Apply Behavior: The tool will only perform mutable operations if the apply parameter is explicitly set to true.

The flag name --apply is conventional in command-line interfaces and clearly communicates intent, making it a suitable choice for the logical parameter name within the tool's arguments.   

3.1.2 Side-Effects Policy
Dry-Run Mode: In this mode, the tool's logic must simulate the intended action without causing any side effects. It should calculate the changes that would be made and return a descriptive message and a representation of the would-be artifacts. For example, tokens.build would report the file paths it would create, but not actually write them.

Apply Mode: In this mode, side effects are permitted but are strictly constrained by the sandboxing policies detailed below. The tool's logic must first validate that it is operating within the allowed sandbox before proceeding with any filesystem or git operations.

3.1.3 Idempotency Strategy
For operations in apply mode, achieving idempotency is crucial for building a reliable system that can safely handle retried requests.   

Filesystem Operations: Idempotency can be achieved by checking for the existence of a target file before writing it. For operations that generate content, a more robust approach is to name output artifacts based on a hash of their content or inputs, ensuring that re-running the same operation produces the same artifact name and overwrites the previous result without error.

API-driven Operations: For tools like reviewKit.create that may interact with external APIs, idempotency should be managed using an idempotency key. The server can generate a unique identifier (e.g., a V4 UUID) for each tools/call request. This key can be passed in the Idempotency-Key header to the downstream service, a standard pattern used by robust APIs like Stripe to prevent duplicate resource creation on retried requests.   

3.2 Path Sandboxing and Allowlisting: Establishing a "Jail"
Allowing an AI agent to specify file paths is inherently risky. A simple check to block ../ sequences is insufficient, as it can be bypassed using various encoding and nesting techniques. A defense-in-depth approach is required, using the operating system's path resolution logic to establish an inescapable "jail" or sandbox.   

The validation process involves three critical steps performed in sequence:

Normalization: The user-provided path is normalized using path.normalize(). This resolves redundant separators (e.g., foo//bar), . segments, and .. segments according to the host OS's rules.   

Resolution: The normalized path is joined with the absolute path of the designated sandbox directory using path.join(). This produces a canonical, absolute path to the target resource.   

Prefix Validation: The final, critical check verifies that the resolved absolute path begins with the absolute path of the sandbox directory. This startsWith() check ensures that no matter how the input was crafted, the final destination is provably within the allowed boundary.   

3.2.1 Filesystem Sandboxing Implementation
All file write operations must be confined to a dynamically named directory within /artifacts/current-state/. This is enforced by a utility function that must be called before any fs operation.

src/core/sandbox.ts:

TypeScript

import * as path from 'node:path';
import *s fs from 'node:fs/promises';

// Error type for policy violations
export class PolicyError extends Error {
  constructor(message: string) {
    super(message);
    this.name = 'PolicyError';
  }
}

/**
 * Returns the absolute path to the root of the sandbox directory for today.
 * Ensures the directory exists.
 * @returns {Promise<string>} The absolute path to the sandbox directory.
 */
export async function getSandboxDirectory(): Promise<string> {
  const today = new Date().toISOString().split('T'); // YYYY-MM-DD
  const sandboxRoot = path.resolve(process.cwd(), 'artifacts', 'current-state', today);
  await fs.mkdir(sandboxRoot, { recursive: true });
  return sandboxRoot;
}

/**
 * Resolves a user-provided path against the sandbox directory and verifies
 * it remains within the sandbox. Throws a PolicyError if traversal is attempted.
 * @param {string} userPath - The untrusted path from user/agent input.
 * @param {string} sandboxDir - The absolute path of the sandbox root.
 * @returns {string} A safe, absolute path confirmed to be inside the sandbox.
 */
export function ensurePathInSandbox(userPath: string, sandboxDir: string): string {
  // 1. Resolve the user path relative to the sandbox directory.
  // path.join is safer here as it prevents jumping to root with '/'.
  const intendedPath = path.join(sandboxDir, userPath);

  // 2. Normalize the path to resolve '..' and other relative segments.
  const normalizedPath = path.normalize(intendedPath);

  // 3. The critical check: verify the normalized path is still within the sandbox.
  if (!normalizedPath.startsWith(sandboxDir)) {
    throw new PolicyError(`Path traversal attempt detected. Path '${userPath}' resolves outside of the designated sandbox.`);
  }

  return normalizedPath;
}
3.2.2 Git Branch Sandboxing Strategy
For operations that modify the source codebase, direct writes to the main branch are forbidden. Instead, a temporary feature branch is used as a sandbox. This encapsulates all changes, allowing for human review via a standard pull request workflow before they are integrated.   

To implement this safely, the server must interact with the git repository programmatically. Shelling out to the git binary (e.g., via spawn('git',...) re-introduces the risk of command injection. A far more secure and portable approach is to use a pure JavaScript implementation of Git, such as isomorphic-git. This library interacts directly with the .git directory, eliminating shell-based vulnerabilities and removing any dependency on a pre-installed git client on the host machine. It is a more robust and testable solution compared to native-binding-based libraries like nodegit, which are notoriously difficult to install and maintain.   

Example Workflow using isomorphic-git:

TypeScript

import git from 'isomorphic-git';
import fs from 'node:fs';
import http from 'isomorphic-git/http/node'; // For remote operations if needed

async function createIsolatedBranch(repoDir: string, branchName: string): Promise<void> {
  await git.branch({
    fs,
    dir: repoDir,
    ref: branchName,
    checkout: true
  });
}

async function commitChanges(repoDir: string, author: { name: string, email: string }, message: string): Promise<string> {
  // Stage all changes
  // In a real implementation, you would selectively add files.
  const status = await git.statusMatrix({ fs, dir: repoDir });
  for (const [filepath, head, workdir] of status) {
    if (workdir) { // workdir status is not 0 (unmodified)
      await git.add({ fs, dir: repoDir, filepath });
    }
  }

  // Commit the staged changes
  const sha = await git.commit({
    fs,
    dir: repoDir,
    message,
    author
  });
  return sha;
}
3.3 Safe Subprocess Spawning
When a tool must execute an external command-line utility, the method of invocation is critical to security. The Node.js child_process module offers two primary methods: exec and spawn. The exec function is highly dangerous as it invokes a command within a subshell, making it trivial to inject additional commands if any part of the command string is derived from user input.   

The spawn function is the secure alternative. It executes the command directly without an intermediate shell and requires that all arguments be passed as an array of strings. This strict separation ensures that arguments containing shell metacharacters (e.g., ;, &&, |) are treated as literal strings by the target program and are not interpreted by a shell, thereby preventing command injection attacks.   

A reusable wrapper function will enforce these best practices for all tool executions.

src/core/safe-spawn.ts:

TypeScript

import { spawn, SpawnOptions } from 'node:child_process';

interface SpawnResult {
  stdout: string;
  stderr: string;
  exitCode: number | null;
}

/**
 * A secure wrapper around child_process.spawn that executes a command
 * with arguments, captures its output, and ensures it runs in a specified CWD.
 * @param {string} command - The command to execute.
 * @param {string} args - An array of string arguments for the command.
 * @param {SpawnOptions} options - Spawn options, CWD is required for sandboxing.
 * @returns {Promise<SpawnResult>} A promise that resolves with the process output.
 */
export function safeSpawn(command: string, args: string, options: SpawnOptions): Promise<SpawnResult> {
  if (!options.cwd) {
    throw new Error('Security Error: CWD must be specified for safeSpawn.');
  }

  return new Promise((resolve, reject) => {
    const child = spawn(command, args, {
     ...options,
      shell: false, // Explicitly disable shell for security
    });

    let stdout = '';
    let stderr = '';

    child.stdout?.on('data', (data) => {
      stdout += data.toString();
    });

    child.stderr?.on('data', (data) => {
      stderr += data.toString();
    });

    child.on('close', (code) => {
      resolve({ stdout, stderr, exitCode: code });
    });

    child.on('error', (err) => {
      reject(err);
    });
  });
}
By mandating the use of this safeSpawn function and requiring the cwd option to be set to a path validated by ensurePathInSandbox, the server creates a robust, sandboxed execution environment for all external tools.

Section 4: Auditing, Logging, and Error Handling
For a system that automates operational tasks, comprehensive auditing and clear error reporting are not optional features; they are fundamental requirements for security, debugging, and building trust. Every action taken by the server must be immutably recorded, and every failure must be communicated in a way that is actionable for both human operators and AI clients.

4.1 Transcript Specification
Each tool execution, whether a dry-run or an apply, must generate a detailed, structured log entry known as a transcript. Using a structured format like JSON is essential for enabling automated parsing, querying, and alerting by log management systems.   

4.1.1 Transcript Format
The transcript will be a single JSON object with a consistent schema, providing a complete record of the transaction.

Table 2: Transcript JSON Format

Field Name	Type	Description	Example
id	string	A unique UUID (V4) identifying this specific transcript record.	"a1b2c3d4-..."
toolCallId	string	The id from the incoming JSON-RPC tools/call request, for tracing.	"req-12345"
timestamp_start	string	The ISO 8601 timestamp when execution began.	"2025-07-15T10:00:00.123Z"
timestamp_end	string	The ISO 8601 timestamp when execution completed.	"2025-07-15T10:00:01.456Z"
toolName	string	The name of the tool that was executed.	"tokens.build"
toolArgs	object	The full, validated argument object passed to the tool (with redactions).	{ "source": "...", "apply": true }
executionMode	string	The mode of execution, either "dry-run" or "apply".	"apply"
exitCode	number | null	The exit code from the spawned subprocess, if applicable. 0 for success.	0
stdout	string	The captured standard output from the tool's execution.	"Build successful..."
stderr	string	The captured standard error from the tool's execution.	""
artifacts	string	An array of absolute paths to files created or modified during execution.	["/app/artifacts/.../tokens.css"]
redactions	string	An array of keys that were redacted from the toolArgs object.	["apiKey"]
integrityHash	string	A SHA-256 hash of the canonicalized JSON transcript object (excluding this field).	"e3b0c442..."

Export to Sheets
4.1.2 Redaction Strategy
Logging raw tool arguments can pose a significant security risk if they contain secrets like API keys or tokens. Before a transcript is written, the toolArgs object must be processed by a redaction function. This function will recursively scan the object for keys matching a predefined list of sensitive patterns (e.g., *key*, *token*, *secret*) and replace their values with a placeholder string, such as ``. The redactions field in the transcript provides an audit trail of what was removed, maintaining transparency without compromising security.   

4.1.3 Integrity Hashing
To ensure the immutability of the audit trail, an integrityHash is included in each transcript. This hash is calculated (e.g., using SHA-256) on a canonical string representation of the transcript object before the hash field itself is added. This allows a separate auditing process to periodically verify the integrity of the logs by recalculating the hashes and ensuring they match, thus detecting any unauthorized modifications.

4.2 A Taxonomy of Errors
Error handling for AI agents requires more nuance than for traditional APIs. A simple HTTP status code is often insufficient; an agent needs structured, machine-readable information to understand the nature of the failure and decide on a course of action—whether to correct its input and retry, report a system failure, or cease its task. A well-defined error taxonomy provides this crucial context.   

The proposed taxonomy categorizes errors based on the source of the fault, which directly informs the appropriate response. Each error response will use the standard HTTP status codes but will be augmented with a JSON body containing a clear type and code.   

Table 3: Error Taxonomy and HTTP Status Mapping

Error Category	Description	HTTP Status Code	Example JSON Response Body
User Error	The request could not be processed due to invalid client-provided data, such as failing schema validation or violating a tool's specific business logic (e.g., a non-existent source file). The agent should correct its input and may retry.	400 Bad Request	{ "error": { "type": "user", "code": "invalid_argument", "message": "Input validation failed: 'platforms' must be a non-empty array." } }
Policy Error	The request was syntactically valid but violated a server-side security policy. This includes path traversal attempts, accessing forbidden resources, or exceeding rate limits. The agent should treat this as a hard failure and likely requires human intervention.	403 Forbidden	{ "error": { "type": "policy", "code": "path_not_allowed", "message": "Path traversal attempt detected. Path '../secrets' resolves outside of the designated sandbox." } }
System Error	An unexpected failure occurred on the server during tool execution. This could be a crash in a subprocess, a database connection failure, or an unhandled exception. The agent should not retry the request immediately, as the issue is on the server side.	500 Internal Server Error	{ "error": { "type": "system", "code": "tool_execution_failed", "message": "The 'a11y.scan' tool failed unexpectedly with exit code 1." } }

Export to Sheets
By adopting this structured error taxonomy, the MCP server moves beyond simple failure signals to provide actionable intelligence to its AI clients, enabling more resilient and sophisticated automated workflows.

Section 5: Client Integration for Local Development
To facilitate development and testing, it is essential that AI agent clients can easily connect to the locally running MCP server. This section provides concrete, step-by-step instructions for connecting the two target clients: Anthropic's Claude (via Claude Desktop and Claude Code) and the OpenAI Agents SDK.

5.1 The Stdio Transport Mechanism
For local development, the most direct and secure connection method is the stdio transport. As defined by the Model Context Protocol, this mechanism involves the client application launching the MCP server as a child subprocess. The client then communicates with the server by writing JSON-RPC messages to the server's standard input (stdin) and reading responses from its standard output (stdout). This avoids the need to expose network ports and simplifies the setup process significantly. The server skeleton defined in Section 1 is already configured to use this transport.   

5.2 Connecting Anthropic Claude Clients
Anthropic provides multiple developer tools that can act as MCP clients. The following instructions cover connecting to the server from Claude Desktop and the Claude Code CLI.

5.2.1 Claude Desktop
Claude Desktop manages local MCP server connections through a central JSON configuration file. To add the OODS tool server, the developer must edit this file directly.   

Locate the Configuration File:

macOS: ~/Library/Application Support/Claude/claude_desktop_config.json

Windows: %APPDATA%\Claude\claude_desktop_config.json

Add the Server Configuration:
Add a new entry to the mcpServers object. The key (oods-tools) is a unique name for the server, and the value is an object specifying the command to run the server via the stdio transport.

JSON

{
  "mcpServers": {
    "oods-tools": {
      "command": "node",
      "args": [
        "/path/to/your/project/dist/server.js"
      ]
    }
  }
}
Note: Replace /path/to/your/project/ with the absolute path to the compiled server's entry point (server.js) on the local machine.

Restart Claude Desktop:
After saving the configuration file, completely quit and restart the Claude Desktop application for the changes to take effect. The new tools will then be available for use in conversations.

5.2.2 Claude Code CLI
The Claude Code command-line interface provides a command to manage MCP server connections for a specific project or user profile.   

Navigate to the Project Directory:
Open a terminal and change to the root directory of the MCP server project.

Add the Server using the mcp add command:
Execute the following command to register the server for the current project. This command tells Claude Code to use the stdio transport and specifies how to run the server.

Bash

claude mcp add --transport stdio oods-tools -- node dist/server.js
oods-tools: A unique name for the server.

--: This separator distinguishes flags for the claude command from the actual command and arguments needed to start the server.

After running this command, the tools exposed by the server will be available to the Claude Code agent within that project context.

5.3 Connecting the OpenAI Agents SDK
The OpenAI Agents SDK for TypeScript/JavaScript provides a dedicated class, MCPServerStdio, for managing connections to local stdio-based servers.   

Install Dependencies:
Ensure the OpenAI Agents SDK is installed in the client project: npm install @openai/agents.

Instantiate and Connect the Server:
In the client-side agent code, import Agent and MCPServerStdio. Create an instance of the server, specifying the full command required to launch it. Then, connect to it and pass the server instance to the Agent constructor.

TypeScript

import { Agent, MCPServerStdio, Runner } from '@openai/agents';
import path from 'node:path';

async function runAgentWithLocalTools() {
  // 1. Define the command to start the MCP server.
  // It's best practice to use an absolute path.
  const serverPath = path.resolve(__dirname, '../path/to/mcp-server/dist/server.js');
  const serverCommand = `node ${serverPath}`;

  // 2. Create an instance of the stdio server connector.
  const oodsServer = new MCPServerStdio({
    fullCommand: serverCommand,
  });

  try {
    // 3. Establish the connection to the spawned server process.
    await oodsServer.connect();
    console.log('Successfully connected to local OODS MCP server.');

    // 4. Create an agent and provide it with the connected server.
    const agent = new Agent({
      name: 'Design System Assistant',
      instructions: 'You are an assistant that can use OODS tools to manage the design system.',
      mcpServers:, // Pass the server instance here
    });

    // 5. Run the agent.
    const result = await Runner.run(agent, {
      input: "Build the CSS tokens from 'tokens/colors.json' but do not write any files yet.",
    });

    console.log('Agent run completed:', result);

  } catch (error) {
    console.error('Failed to run agent with local tools:', error);
  } finally {
    // 6. Ensure the server process is terminated.
    await oodsServer.disconnect();
  }
}

runAgentWithLocalTools();
This code provides a complete, self-contained example for spawning, connecting to, using, and cleaning up the local MCP server process from within an OpenAI Agents SDK application.

Section 6: Summary of Build Implications and Deliverables
This final section synthesizes the architectural decisions and patterns detailed throughout the report into a concise summary and provides the findings.yaml deliverable, which serves as a quick-reference specification for the implementation team.

6.1 Architectural Summary
The proposed architecture for the MCP tool server is rooted in principles of security, performance, and auditability. The key architectural pillars are:

Server Foundation: A Fastify server running on Node.js 20, leveraging its high-performance request/response lifecycle and native integration with Ajv for strict, high-speed JSON Schema validation.

Tool Contract: All tools expose a contract compliant with the MCP standard, with clear descriptions and schemas. This contract is the source of truth for client-server interaction.

Execution Model: A default-to-safe dry-run policy, requiring an explicit --apply flag for any mutable operations. This enforces intentionality and provides a human-in-the-loop checkpoint.

Security & Sandboxing: A multi-layered defense strategy is employed. A robust path validation utility confines all filesystem writes to a timestamped /artifacts directory. Code modifications are isolated within temporary isomorphic-git managed branches. All subprocesses are invoked securely using a spawn-based wrapper to prevent command injection.

Auditing & Error Handling: Every tool execution is recorded in a structured, immutable JSON transcript with redaction and an integrity hash. A formal error taxonomy (User, Policy, System) provides machine-readable feedback to AI clients, enabling more intelligent failure handling.

Client Connectivity: The server communicates via the standard MCP stdio transport, ensuring simple and secure integration with local development clients like Claude Desktop, Claude Code, and the OpenAI Agents SDK.

This architecture provides a comprehensive and production-ready blueprint for building a secure and reliable bridge between internal development tools and advanced AI agents.

6.2 Final Deliverable: findings.yaml
The following YAML file codifies the primary recommendations and specifications from this report, aligning with the requested deliverable schema.

YAML

# missions/research/r.10.1_MCP-Server-Patterns.findings.yaml
recommended_server:
  runtime: "node20"
  framework: "fastify"
  validation: "ajv"
tools:
  - id: "tokens.build"
    input_schema:
      type: "object"
      properties:
        source: { type: "string", description: "Relative path to the source token definition file (e.g., 'tokens/colors.json')." }
        platforms: { type: "array", items: { type: "string", enum: ["css", "js", "scss"] }, minItems: 1 }
        apply: { type: "boolean", default: false }
      required: ["source", "platforms"]
      additionalProperties: false
    output_schema:
      type: "object"
      properties:
        success: { type: "boolean" }
        message: { type: "string" }
        artifacts: { type: "array", items: { type: "object", properties: { platform: { type: "string" }, path: { type: "string" } }, required: ["platform", "path"] } }
      required: ["success", "message", "artifacts"]
  - id: "a11y.scan"
    input_schema:
      type: "object"
      properties:
        url: { type: "string", format: "uri", description: "The publicly accessible URL to scan for accessibility issues." }
      required: ["url"]
      additionalProperties: false
    output_schema:
      type: "object"
      properties:
        url: { type: "string", format: "uri" }
        issueCount: { type: "integer" }
        issues: { type: "array", items: { type: "object", properties: { id: { type: "string" }, impact: { type: "string", enum: ["minor", "moderate", "serious", "critical"] }, description: { type: "string" }, helpUrl: { type: "string", format: "uri" } }, required: ["id", "impact", "description"] } }
      required: ["url", "issueCount", "issues"]
  - id: "reviewKit.create"
    input_schema:
      type: "object"
      properties:
        featureName: { type: "string", description: "A short, URL-safe name for the feature (e.g., 'new-button-variant')." }
        ticketId: { type: "string", pattern: "^[A-Z]+-[0-9]+$", description: "The associated ticket ID (e.g., 'PROJ-123')." }
        apply: { type: "boolean", default: false }
      required: ["featureName", "ticketId"]
      additionalProperties: false
    output_schema:
      type: "object"
      properties:
        success: { type: "boolean" }
        message: { type: "string" }
        reviewKitUrl: { type: "string", format: "uri" }
        branchName: { type: "string" }
      required: ["success", "message"]
  - id: "release.packVerify"
    input_schema:
      type: "object"
      properties:
        version: { type: "string", pattern: "^(0|[1-9]\\d*)\\.(0|[1-9]\\d*)\\.(0|[1-9]\\d*)(?:-((?:0|[1-9]\\d*|\\d*[a-zA-Z-][0-9a-zA-Z-]*)(?:\\.(?:0|[1-9]\\d*|\\d*[a-zA-Z-][0-9a-zA-Z-]*))*))?(?:\\+([0-9a-zA-Z-]+(?:\\.[0-9a-zA-Z-]+)*))?$" }
        apply: { type: "boolean", default: false }
      required: ["version"]
      additionalProperties: false
    output_schema:
      type: "object"
      properties:
        success: { type: "boolean" }
        version: { type: "string" }
        verificationChecks: { type: "array", items: { type: "object", properties: { checkName: { type: "string" }, passed: { type: "boolean" }, details: { type: "string" } }, required: ["checkName", "passed"] } }
        branchName: { type: "string" }
      required: ["success", "version", "verificationChecks"]
dry_run_flag: "--dry-run" # Note: This is the default behavior, not an explicit flag.
apply_flag: "--apply"
path_allowlist:
  - "/artifacts/current-state/${YYYY-MM-DD}"
transcript:
  fields: ["id", "toolCallId", "timestamp_start", "timestamp_end", "toolName", "toolArgs", "executionMode", "exitCode", "stdout", "stderr", "artifacts", "redactions", "integrityHash"]

Sources used in the report

cbtnuggets.com
Express vs. Fastify: Which Framework Should You Use for Node.js? - CBT Nuggets
Opens in a new window

betterstack.com
Express.js vs Fastify: An In-Depth Framework Comparison | Better ...
Opens in a new window

betterstack.com
Fastify vs Express vs Hono - Node.js Frameworks | Better Stack Community
Opens in a new window

medium.com
Express.js vs Fastify: Comparison for Building Node.js Applications | by Frontend Highlights
Opens in a new window

npm-compare.com
ajv vs zod vs joi vs yup vs class-validator | JavaScript Validation ...
Opens in a new window

dev.to
Zod is dead. Long live ajv-ts! - DEV Community
Opens in a new window

reddit.com
What is the absolutely fastest JSON validation library in existence? (no matter which language) : r/webdev - Reddit
Opens in a new window

betterstack.com
JSON Schema Validation with Ajv | Better Stack Community
Opens in a new window

bacancytechnology.com
Mastering TypeScript Best Practices to Follow in 2025 - Bacancy Technology
Opens in a new window

github.com
This is a guideline of best practices that you can apply to your TypeScript project. - GitHub
Opens in a new window

modelcontextprotocol.io
Transports - Model Context Protocol
Opens in a new window

medium.com
Understanding MCP Stdio transport | by Laurent Kubaski - Medium
Opens in a new window

modelcontextprotocol.io
Tools - Model Context Protocol
Opens in a new window

modelcontextprotocol.info
Tools - Model Context Protocol （MCP）
Opens in a new window

reddit.com
r/kubernetes on Reddit: Why use this pattern: kubectl create ... --dry-run=client -o yaml
Opens in a new window

event-driven.io
Idempotent Command Handling - Event-Driven.io
Opens in a new window

blog.appsignal.com
Build an Idempotent API in Node.js with Redis - AppSignal Blog
Opens in a new window

docs.stripe.com
Idempotent requests | Stripe API Reference
Opens in a new window

medium.com
Designing Idempotent APIs: Patterns, Gotchas, and Real-Life Scenarios - Medium
Opens in a new window

stackhawk.com
Node.js Path Traversal: Examples & Mitigation - StackHawk
Opens in a new window

portswigger.net
What is path traversal, and how to prevent it? | Web Security Academy - PortSwigger
Opens in a new window

forum.freecodecamp.org
Problem with directory traversal/path traversal - JavaScript - The freeCodeCamp Forum
Opens in a new window

reddit.com
Question: NodeJS secure file saving into file system. Preventing path traversal - Reddit
Opens in a new window

security.stackexchange.com
How to prevent directory traversal when joining paths in node.js?
Opens in a new window

atlassian.com
Git Feature Branch Workflow | Atlassian Git Tutorial
Opens in a new window

blog.pixelfreestudio.com
How to Use Git Branching Strategies for Better Workflow
Opens in a new window

npm-compare.com
simple-git vs isomorphic-git vs nodegit | Git Libraries for JavaScript Comparison
Opens in a new window

isomorphic-git.org
isomorphic-git · A pure JavaScript implementation of git for node and ...
Opens in a new window

github.com
isomorphic-git/isomorphic-git: A pure JavaScript implementation of git for node and browsers! - GitHub
Opens in a new window

gitddb.com
Integrated NodeGit and isomorphic-git - GitDocumentDB
Opens in a new window

isomorphic-git.org
Frequently Asked Questions - isomorphic-git
Opens in a new window

gitlab.com
Replace nodegit with isomorphic-git (#264) · Issue - Antora - GitLab
Opens in a new window

docs.datadoghq.com
Avoid instances of 'child_process' and non-literal 'exec()' - Datadog Docs
Opens in a new window

stackoverflow.com
child_process spawn in node.js security / escaping - Stack Overflow
Opens in a new window

medium.com
7 Best Practices for Sanitizing Input in Node.js | by Arunangshu Das | Devmap - Medium
Opens in a new window

stackoverflow.com
Node.js Spawn vs. Execute - javascript - Stack Overflow
Opens in a new window

nodejs.org
Child process | Node.js v24.10.0 Documentation
Opens in a new window

betterstack.com
11 Best Practices for Logging in Node.js | Better Stack Community
Opens in a new window

uptrace.dev
Structured Logging Best Practices: Implementation Guide with Examples - Uptrace
Opens in a new window

sematext.com
Node.js Logging Tutorial: How to Check, Write & Debug [Best Practices]
Opens in a new window

betterstack.com
Best Logging Practices for Safeguarding Sensitive Data | Better Stack Community
Opens in a new window

skyflow.com
How to Keep Sensitive Data Out of Your Logs: 9 Best Practices - Skyflow
Opens in a new window

speakeasy.com
Errors Best Practices in REST API Design - Speakeasy
Opens in a new window

nordicapis.com
Designing API Error Messages for AI Agents - Nordic APIs
Opens in a new window

codeopinion.com
Your API Errors Suck (Here's How to Fix Them) - CodeOpinion
Opens in a new window

modelcontextprotocol.io
Connect to local MCP servers - Model Context Protocol
Opens in a new window

support.claude.com
Getting Started with Local MCP Servers on Claude Desktop
Opens in a new window

docs.claude.com
Model Context Protocol (MCP) - Claude Docs
Opens in a new window

openai.github.io
Tools | OpenAI Agents SDK - GitHub Pages